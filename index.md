---
layout: home
profile_picture:
  src: /assets/img/HP_shot_large.jpg
  alt: website picture

sections:
  - title: Research
    items:
      - title: Information-driven design of imaging systems
        video:
          src: /assets/img/work/ideal_small.mp4
          alt: Encoding info
        venue: "NeurIPS 2025"
        venue_url: https://neurips.cc/virtual/2025/loc/san-diego/poster/118055
        links:
          - text: website
            url: https://waller-lab.github.io/EncodingInformationWebsite/
          - text: paper
            url: https://doi.org/10.48550/arXiv.2405.20559
          - text: code
            url: https://github.com/Waller-Lab/EncodingInformation
        description: 'A method to design imaging systems that capture maximum information for AI, free from human perceptual constraints. Applicable to diverse systems from consumer cameras to radio telescopes imaging black holes.'

      - title: ARC-AGI-2 - A challenge for frontier AI reasoning systems
        image:
          src: /assets/img/work/arc2.png
          alt: ARC-AGI-2
        venue: "2025"
        links:
          - text: website
            url: https://arcprize.org/arc-agi/2/
          - text: paper
            url: https://arxiv.org/html/2505.11831v1
        description: 'A benchmark for testing fluid intelligence and compositional reasoning in AI systems. Tests symbolic interpretation, multi-step reasoning, and contextual understanding beyond pattern matching.'

      - title: The Berkeley single-cell computational microscopy (BSCCM) dataset
        video: 
          src: /assets/img/work/bsccm_montage.mp4
          alt: Cell montage
        venue: "arXiv 2024"
        venue_url: https://arxiv.org/abs/2402.06191
        links:
          - text: website
            url: https://waller-lab.github.io/BSCCM/
          - text: paper
            url: https://arxiv.org/abs/2402.06191
          - text: code
            url: https://github.com/Waller-Lab/BSCCM
        description: 'A 12-million-image biomedical computer vision benchmark with 400k+ images of white blood cells under varied illumination, paired with protein expression labels for training and evaluation.'

      - title: Pycro-Manager
        image:
          src: /assets/img/work/pycromanager_banner.png
          alt: Pycro-Manager banner
        venue: "Nature Methods 2021"
        venue_url: https://doi.org/10.1038/s41592-021-01087-6
        links:
          - text: documentation
            url: https://pycro-manager.readthedocs.io/en/latest/
          - text: paper
            url: https://doi.org/10.1038/s41592-021-01087-6
          - text: code
            url: https://github.com/micro-manager/pycro-manager
        description: 'Open-source Python package for microscope control, enabling automated experiments and real-time adaptive imaging. Works with hundreds of hardware components and handles terabyte-scale data acquisition.'

      - title: Learned adaptive multiphoton illumination microscopy
        video:
          src: /assets/img/work/LN.mp4
          alt: Lymph_node_video
        venue: "Nature Communications 2021"
        venue_url: https://doi.org/10.1038/s41467-021-22246-5
        links:
          - text: paper
            url: https://doi.org/10.1038/s41467-021-22246-5
          - text: tutorial
            url: https://pycro-manager.readthedocs.io/en/latest/application_notebooks/Learned_adaptive_multiphoton_illumination.html
          - text: data
            url: https://doi.org/10.6084/m9.figshare.12841781
        description: 'A technique where neural networks dynamically adjust laser power during scanning, enabling immune cell imaging at previously impossible scales and depths in living tissue.'

      - title: Deep learning for single-shot autofocus microscopy
        video:
          src: /assets/img/work/focus.mp4
          alt: coherent focus
        venue: "Optica 2019"
        venue_url: https://doi.org/10.1364/OPTICA.6.000794
        links:
          - text: paper
            url: https://doi.org/10.1364/OPTICA.6.000794
          - text: tutorial
            url: https://pycro-manager.readthedocs.io/en/latest/application_notebooks/Single_shot_autofocus_pycromanager.html
          - text: code
            url: https://github.com/henrypinkard/DeepAutofocus
        description: 'Physics-informed neural architecture that predicts focus corrections from single images using custom illumination patterns, reducing parameters by 100Ã— while maintaining accuracy.'

---

I'm an interdisciplinary researcher with expertise in information theory, computational imaging, deep learning, biology, and software engineering. I did my PhD and postdoc in the UC Berkeley <a href="https://eecs.berkeley.edu/">EECS</a> department and <a href="https://bair.berkeley.edu/">Berkeley AI Research Lab</a>, advised by <a href="http://www.laurawaller.com/">Laura Waller</a>.

<p>My research has included:</p>

<ul>
<li>Inventing a technique to design cameras and other sensors for AI rather than human vision</li>
<li>Building the ARC-AGI-2 benchmark for testing fluid intelligence in large language models</li>
<li>Creating a 12-million-image biomedical dataset to train computer vision algorithms</li>
<li>Producing the most widely used software for automating microscopes, used in applications from diagnosing disease to discovering new materials</li>
<li>Developing neural network architectures that incorporate physics knowledge to enable fast and low-cost scientific discovery</li>
</ul>

<p style="text-align: center">
<a href="mailto:research@henrypinkard.com">Email</a> &nbsp;/&nbsp;
<a href="https://scholar.google.com/citations?user=-CpByXMAAAAJ&hl=en">Google scholar</a> &nbsp;/&nbsp;
<a href="https://github.com/henrypinkard">GitHub</a> &nbsp;/&nbsp;
<a href="https://bsky.app/profile/henrypinkard.bsky.social">Bluesky</a>
</p>

